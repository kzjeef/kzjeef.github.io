---
layout: post
title: About File system logging
date: 2009-11-30 02:00:00.000000000 +08:00
type: post
published: true
status: publish
categories:
- 未分类
tags: []
meta: {}
author:
  login: kzjeef
  email: kzjeef@gmail.com
  display_name: kzjeef
  first_name: ''
  last_name: ''
---
<p>This is a note @MIT OCW 6.824 Lecture 7:</p>
<p>The main point of a log is make complex operations atomic.</p>
<p>I.e. operations that involve many individule writes. You want all writes or none, even if a crash in the middle.</p>
<p>A "transaction" is multi-write operation that should be atomic. The logging system needs to know which set of write from a transication.</p>
<p>Re-do with checkpoint:</p>
<p>Most logs work like this, e.g. FSD,<br />allows much faster recovery: ca use on-disk data<br />write-ahead rule:</p>
<blockquote style="MARGIN-RIGHT: 0px" dir="ltr"><p>delay flushing dirty block from in-memory data cache until corresponding commit recore is on disk</p>
</blockquote>
<p style="MARGIN-RIGHT: 0px" dir="ltr">Check point rules:</p>
<blockquote style="MARGIN-RIGHT: 0px" dir="ltr"><p style="MARGIN-RIGHT: 0px" dir="ltr">all data writes before check point must be stable on disk checkpoint may not advance beyond first uncommitted Begin</p>
</blockquote>
<p style="MARGIN-RIGHT: 0px" dir="ltr">Recovery:</p>
<blockquote style="MARGIN-RIGHT: 0px" dir="ltr"><p style="MARGIN-RIGHT: 0px" dir="ltr">for each block mentioned in the log<br />find the last xaction that wrote that block<br />if committed: re-do<br />if not committed: un-do</p>
</blockquote>
<p style="MARGIN-RIGHT: 0px" dir="ltr">Why is logging fast:</p>
<blockquote style="MARGIN-RIGHT: 0px" dir="ltr"><p style="MARGIN-RIGHT: 0px" dir="ltr">group commit -- batched log writes.<br />could delay flushing log -- may lost committed transactions but at least you have a prefix.</p>
<p style="MARGIN-RIGHT: 0px" dir="ltr">Single seek to implement a transaction.<br />maybe less if no intervening disk activity, or group commit</p>
<p style="MARGIN-RIGHT: 0px" dir="ltr">Write-behind of data allows batched/schedules.<br />one data block may reflect many transactions, i.e. create many files in a directory.<br />don't have to be so careful since the log is the real infomation.</p>
</blockquote>
